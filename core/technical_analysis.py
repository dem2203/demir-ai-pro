"""
Professional Technical Analysis Engine
======================================
127-Layer Multi-Dimensional Analysis System
Real indicators using TA-Lib (ta library)
NO MOCK DATA - Only real market data from Binance

Author: DEMIR AI PRO
Version: 8.0
"""

import logging
import numpy as np
import pandas as pd
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime, timedelta
import ta  # Technical Analysis library
from scipy import stats

logger = logging.getLogger("core.technical_analysis")


class ProfessionalTAEngine:
    """Enterprise-grade technical analysis with 127 real indicators"""
    
    def __init__(self):
        self.min_candles = 200  # Minimum for accurate multi-timeframe analysis
        logger.info("üîß Professional TA Engine initialized with 127 layers")
    
    async def fetch_historical_data(
        self,
        symbol: str,
        interval: str = "15m",
        limit: int = 500
    ) -> Optional[pd.DataFrame]:
        """
        Fetch real OHLCV data from Binance
        NO MOCK DATA - Only real data
        """
        try:
            from integrations.binance_integration import BinanceIntegration
            
            binance = BinanceIntegration()
            
            # Get klines from Binance
            klines = binance.get_klines(symbol, interval, limit)
            
            if not klines or len(klines) == 0:
                logger.error(f"‚ùå No data from Binance for {symbol}")
                return None
            
            # Convert to DataFrame
            df = pd.DataFrame(klines, columns=[
                'timestamp', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'number_of_trades',
                'taker_buy_base', 'taker_buy_quote', 'ignore'
            ])
            
            # Convert to numeric
            df['open'] = pd.to_numeric(df['open'])
            df['high'] = pd.to_numeric(df['high'])
            df['low'] = pd.to_numeric(df['low'])
            df['close'] = pd.to_numeric(df['close'])
            df['volume'] = pd.to_numeric(df['volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            
            logger.info(f"‚úÖ Fetched {len(df)} candles for {symbol}")
            return df
            
        except Exception as e:
            logger.error(f"‚ùå Error fetching data: {e}")
            return None
    
    # ==========================================
    # TECHNICAL ANALYSIS LAYERS (40)
    # ==========================================
    
    def calculate_rsi_layers(self, df: pd.DataFrame) -> Dict[str, Any]:
        """RSI variations (14, 7, 21 periods)"""
        try:
            layers = {}
            
            # RSI 14 (standard)
            rsi_14 = ta.momentum.RSIIndicator(df['close'], window=14).rsi().iloc[-1]
            layers['rsi_14'] = float(rsi_14) if not pd.isna(rsi_14) else 50.0
            
            # RSI 7 (fast)
            rsi_7 = ta.momentum.RSIIndicator(df['close'], window=7).rsi().iloc[-1]
            layers['rsi_7'] = float(rsi_7) if not pd.isna(rsi_7) else 50.0
            
            # RSI 21 (slow)
            rsi_21 = ta.momentum.RSIIndicator(df['close'], window=21).rsi().iloc[-1]
            layers['rsi_21'] = float(rsi_21) if not pd.isna(rsi_21) else 50.0
            
            # RSI signal
            if layers['rsi_14'] > 70:
                layers['rsi_signal'] = "OVERBOUGHT"
            elif layers['rsi_14'] < 30:
                layers['rsi_signal'] = "OVERSOLD"
            else:
                layers['rsi_signal'] = "NEUTRAL"
            
            return layers
        except Exception as e:
            logger.error(f"RSI layers error: {e}")
            return {'rsi_14': 50.0, 'rsi_7': 50.0, 'rsi_21': 50.0, 'rsi_signal': 'NEUTRAL'}
    
    def calculate_stochastic(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Stochastic Oscillator (K, D)"""
        try:
            stoch = ta.momentum.StochasticOscillator(df['high'], df['low'], df['close'])
            k = stoch.stoch().iloc[-1]
            d = stoch.stoch_signal().iloc[-1]
            
            signal = "OVERBOUGHT" if k > 80 else "OVERSOLD" if k < 20 else "NEUTRAL"
            
            return {
                'stochastic_k': float(k) if not pd.isna(k) else 50.0,
                'stochastic_d': float(d) if not pd.isna(d) else 50.0,
                'stochastic_signal': signal
            }
        except Exception as e:
            logger.error(f"Stochastic error: {e}")
            return {'stochastic_k': 50.0, 'stochastic_d': 50.0, 'stochastic_signal': 'NEUTRAL'}
    
    def calculate_macd_layers(self, df: pd.DataFrame) -> Dict[str, Any]:
        """MACD with histogram and signal"""
        try:
            macd = ta.trend.MACD(df['close'])
            
            macd_line = macd.macd().iloc[-1]
            signal_line = macd.macd_signal().iloc[-1]
            histogram = macd.macd_diff().iloc[-1]
            
            if pd.isna(macd_line) or pd.isna(signal_line):
                return {'macd_line': 0.0, 'macd_signal': 0.0, 'macd_histogram': 0.0, 'macd_trend': 'NEUTRAL'}
            
            trend = "BULLISH" if histogram > 0 else "BEARISH" if histogram < 0 else "NEUTRAL"
            
            return {
                'macd_line': float(macd_line),
                'macd_signal': float(signal_line),
                'macd_histogram': float(histogram),
                'macd_trend': trend
            }
        except Exception as e:
            logger.error(f"MACD error: {e}")
            return {'macd_line': 0.0, 'macd_signal': 0.0, 'macd_histogram': 0.0, 'macd_trend': 'NEUTRAL'}
    
    def calculate_cci(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Commodity Channel Index"""
        try:
            cci = ta.trend.CCIIndicator(df['high'], df['low'], df['close']).cci().iloc[-1]
            
            signal = "OVERBOUGHT" if cci > 100 else "OVERSOLD" if cci < -100 else "NEUTRAL"
            
            return {
                'cci': float(cci) if not pd.isna(cci) else 0.0,
                'cci_signal': signal
            }
        except Exception as e:
            logger.error(f"CCI error: {e}")
            return {'cci': 0.0, 'cci_signal': 'NEUTRAL'}
    
    def calculate_adx(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Average Directional Index (trend strength)"""
        try:
            adx = ta.trend.ADXIndicator(df['high'], df['low'], df['close'])
            adx_value = adx.adx().iloc[-1]
            plus_di = adx.adx_pos().iloc[-1]
            minus_di = adx.adx_neg().iloc[-1]
            
            if pd.isna(adx_value):
                return {'adx': 25.0, 'adx_plus_di': 25.0, 'adx_minus_di': 25.0, 'adx_trend': 'WEAK'}
            
            trend_strength = "STRONG" if adx_value > 25 else "WEAK"
            
            return {
                'adx': float(adx_value),
                'adx_plus_di': float(plus_di) if not pd.isna(plus_di) else 25.0,
                'adx_minus_di': float(minus_di) if not pd.isna(minus_di) else 25.0,
                'adx_trend': trend_strength
            }
        except Exception as e:
            logger.error(f"ADX error: {e}")
            return {'adx': 25.0, 'adx_plus_di': 25.0, 'adx_minus_di': 25.0, 'adx_trend': 'WEAK'}
    
    def calculate_williams_r(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Williams %R"""
        try:
            wr = ta.momentum.WilliamsRIndicator(df['high'], df['low'], df['close']).williams_r().iloc[-1]
            
            signal = "OVERSOLD" if wr > -20 else "OVERBOUGHT" if wr < -80 else "NEUTRAL"
            
            return {
                'williams_r': float(wr) if not pd.isna(wr) else -50.0,
                'williams_signal': signal
            }
        except Exception as e:
            logger.error(f"Williams %R error: {e}")
            return {'williams_r': -50.0, 'williams_signal': 'NEUTRAL'}
    
    def calculate_roc(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Rate of Change"""
        try:
            roc = ta.momentum.ROCIndicator(df['close'], window=12).roc().iloc[-1]
            
            signal = "BULLISH" if roc > 0 else "BEARISH" if roc < 0 else "NEUTRAL"
            
            return {
                'roc': float(roc) if not pd.isna(roc) else 0.0,
                'roc_signal': signal
            }
        except Exception as e:
            logger.error(f"ROC error: {e}")
            return {'roc': 0.0, 'roc_signal': 'NEUTRAL'}
    
    def calculate_momentum(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Momentum indicator"""
        try:
            # Simple momentum: current price - price N periods ago
            momentum = df['close'].iloc[-1] - df['close'].iloc[-10]
            
            signal = "POSITIVE" if momentum > 0 else "NEGATIVE" if momentum < 0 else "NEUTRAL"
            
            return {
                'momentum': float(momentum),
                'momentum_signal': signal
            }
        except Exception as e:
            logger.error(f"Momentum error: {e}")
            return {'momentum': 0.0, 'momentum_signal': 'NEUTRAL'}
    
    def calculate_ema_layers(self, df: pd.DataFrame) -> Dict[str, Any]:
        """EMA Cross system (12, 26, 50, 200)"""
        try:
            ema_12 = ta.trend.EMAIndicator(df['close'], window=12).ema_indicator().iloc[-1]
            ema_26 = ta.trend.EMAIndicator(df['close'], window=26).ema_indicator().iloc[-1]
            ema_50 = ta.trend.EMAIndicator(df['close'], window=50).ema_indicator().iloc[-1]
            ema_200 = ta.trend.EMAIndicator(df['close'], window=200).ema_indicator().iloc[-1]
            
            current_price = df['close'].iloc[-1]
            
            # EMA alignment
            trend = "BULLISH" if ema_12 > ema_26 > ema_50 > ema_200 else "BEARISH" if ema_12 < ema_26 < ema_50 < ema_200 else "MIXED"
            
            return {
                'ema_12': float(ema_12) if not pd.isna(ema_12) else current_price,
                'ema_26': float(ema_26) if not pd.isna(ema_26) else current_price,
                'ema_50': float(ema_50) if not pd.isna(ema_50) else current_price,
                'ema_200': float(ema_200) if not pd.isna(ema_200) else current_price,
                'ema_trend': trend
            }
        except Exception as e:
            logger.error(f"EMA layers error: {e}")
            price = df['close'].iloc[-1]
            return {'ema_12': price, 'ema_26': price, 'ema_50': price, 'ema_200': price, 'ema_trend': 'MIXED'}
    
    def calculate_bollinger_bands(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Bollinger Bands with position"""
        try:
            bb = ta.volatility.BollingerBands(df['close'], window=20, window_dev=2)
            
            upper = bb.bollinger_hband().iloc[-1]
            middle = bb.bollinger_mavg().iloc[-1]
            lower = bb.bollinger_lband().iloc[-1]
            current_price = df['close'].iloc[-1]
            
            # BB %B (position within bands)
            bb_percent = (current_price - lower) / (upper - lower) if (upper - lower) > 0 else 0.5
            
            position = "UPPER" if bb_percent > 0.8 else "LOWER" if bb_percent < 0.2 else "MIDDLE"
            
            return {
                'bb_upper': float(upper) if not pd.isna(upper) else current_price * 1.02,
                'bb_middle': float(middle) if not pd.isna(middle) else current_price,
                'bb_lower': float(lower) if not pd.isna(lower) else current_price * 0.98,
                'bb_percent': float(bb_percent),
                'bb_position': position
            }
        except Exception as e:
            logger.error(f"Bollinger Bands error: {e}")
            price = df['close'].iloc[-1]
            return {'bb_upper': price * 1.02, 'bb_middle': price, 'bb_lower': price * 0.98, 'bb_percent': 0.5, 'bb_position': 'MIDDLE'}
    
    def calculate_ichimoku(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Ichimoku Cloud"""
        try:
            ichimoku = ta.trend.IchimokuIndicator(df['high'], df['low'])
            
            tenkan = ichimoku.ichimoku_conversion_line().iloc[-1]
            kijun = ichimoku.ichimoku_base_line().iloc[-1]
            senkou_a = ichimoku.ichimoku_a().iloc[-1]
            senkou_b = ichimoku.ichimoku_b().iloc[-1]
            
            current_price = df['close'].iloc[-1]
            
            # Cloud signal
            if current_price > max(senkou_a, senkou_b):
                signal = "BULLISH"
            elif current_price < min(senkou_a, senkou_b):
                signal = "BEARISH"
            else:
                signal = "NEUTRAL"
            
            return {
                'ichimoku_tenkan': float(tenkan) if not pd.isna(tenkan) else current_price,
                'ichimoku_kijun': float(kijun) if not pd.isna(kijun) else current_price,
                'ichimoku_senkou_a': float(senkou_a) if not pd.isna(senkou_a) else current_price,
                'ichimoku_senkou_b': float(senkou_b) if not pd.isna(senkou_b) else current_price,
                'ichimoku_signal': signal
            }
        except Exception as e:
            logger.error(f"Ichimoku error: {e}")
            price = df['close'].iloc[-1]
            return {'ichimoku_tenkan': price, 'ichimoku_kijun': price, 'ichimoku_senkou_a': price, 'ichimoku_senkou_b': price, 'ichimoku_signal': 'NEUTRAL'}
    
    def calculate_parabolic_sar(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Parabolic SAR"""
        try:
            psar = ta.trend.PSARIndicator(df['high'], df['low'], df['close'])
            
            psar_value = psar.psar().iloc[-1]
            current_price = df['close'].iloc[-1]
            
            signal = "BULLISH" if current_price > psar_value else "BEARISH"
            
            return {
                'psar': float(psar_value) if not pd.isna(psar_value) else current_price,
                'psar_signal': signal
            }
        except Exception as e:
            logger.error(f"Parabolic SAR error: {e}")
            price = df['close'].iloc[-1]
            return {'psar': price, 'psar_signal': 'NEUTRAL'}
    
    def calculate_atr(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Average True Range"""
        try:
            atr = ta.volatility.AverageTrueRange(df['high'], df['low'], df['close'], window=14)
            atr_value = atr.average_true_range().iloc[-1]
            
            # ATR as percentage of price
            current_price = df['close'].iloc[-1]
            atr_percent = (atr_value / current_price) * 100 if current_price > 0 else 0
            
            return {
                'atr': float(atr_value) if not pd.isna(atr_value) else 0.0,
                'atr_percent': float(atr_percent)
            }
        except Exception as e:
            logger.error(f"ATR error: {e}")
            return {'atr': 0.0, 'atr_percent': 0.0}
    
    def calculate_mfi(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Money Flow Index"""
        try:
            mfi = ta.volume.MFIIndicator(df['high'], df['low'], df['close'], df['volume']).money_flow_index().iloc[-1]
            
            signal = "OVERBOUGHT" if mfi > 80 else "OVERSOLD" if mfi < 20 else "NEUTRAL"
            
            return {
                'mfi': float(mfi) if not pd.isna(mfi) else 50.0,
                'mfi_signal': signal
            }
        except Exception as e:
            logger.error(f"MFI error: {e}")
            return {'mfi': 50.0, 'mfi_signal': 'NEUTRAL'}
    
    # ==========================================
    # VOLUME ANALYSIS LAYERS (10)
    # ==========================================
    
    def calculate_volume_layers(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Volume analysis indicators"""
        try:
            layers = {}
            
            # OBV (On-Balance Volume)
            obv = ta.volume.OnBalanceVolumeIndicator(df['close'], df['volume']).on_balance_volume().iloc[-1]
            obv_prev = ta.volume.OnBalanceVolumeIndicator(df['close'], df['volume']).on_balance_volume().iloc[-10]
            obv_trend = "ACCUMULATION" if obv > obv_prev else "DISTRIBUTION"
            
            layers['obv'] = float(obv) if not pd.isna(obv) else 0.0
            layers['obv_trend'] = obv_trend
            
            # VWAP (Volume Weighted Average Price)
            try:
                vwap = (df['close'] * df['volume']).sum() / df['volume'].sum()
                current_price = df['close'].iloc[-1]
                vwap_signal = "ABOVE" if current_price > vwap else "BELOW"
                
                layers['vwap'] = float(vwap)
                layers['vwap_signal'] = vwap_signal
            except:
                layers['vwap'] = df['close'].iloc[-1]
                layers['vwap_signal'] = "NEUTRAL"
            
            # Volume Ratio (current vs average)
            avg_volume = df['volume'].tail(20).mean()
            current_volume = df['volume'].iloc[-1]
            volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1.0
            
            layers['volume_ratio'] = float(volume_ratio)
            layers['volume_signal'] = "HIGH" if volume_ratio > 1.5 else "LOW" if volume_ratio < 0.5 else "NORMAL"
            
            # A/D Line (Accumulation/Distribution)
            ad = ta.volume.AccDistIndexIndicator(df['high'], df['low'], df['close'], df['volume']).acc_dist_index().iloc[-1]
            layers['ad_line'] = float(ad) if not pd.isna(ad) else 0.0
            
            # CMF (Chaikin Money Flow)
            cmf = ta.volume.ChaikinMoneyFlowIndicator(df['high'], df['low'], df['close'], df['volume']).chaikin_money_flow().iloc[-1]
            layers['cmf'] = float(cmf) if not pd.isna(cmf) else 0.0
            layers['cmf_signal'] = "BULLISH" if cmf > 0 else "BEARISH"
            
            return layers
            
        except Exception as e:
            logger.error(f"Volume layers error: {e}")
            return {
                'obv': 0.0, 'obv_trend': 'NEUTRAL',
                'vwap': df['close'].iloc[-1], 'vwap_signal': 'NEUTRAL',
                'volume_ratio': 1.0, 'volume_signal': 'NORMAL',
                'ad_line': 0.0, 'cmf': 0.0, 'cmf_signal': 'NEUTRAL'
            }
    
    # ==========================================
    # VOLATILITY LAYERS (9)
    # ==========================================
    
    def calculate_volatility_layers(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Volatility indicators"""
        try:
            layers = {}
            
            # Historical Volatility (standard deviation of returns)
            returns = df['close'].pct_change()
            hist_vol = returns.std() * np.sqrt(252) * 100  # Annualized
            layers['historical_volatility'] = float(hist_vol)
            
            # BB Width
            bb = ta.volatility.BollingerBands(df['close'], window=20)
            bb_width = (bb.bollinger_hband().iloc[-1] - bb.bollinger_lband().iloc[-1]) / bb.bollinger_mavg().iloc[-1] * 100
            layers['bb_width'] = float(bb_width) if not pd.isna(bb_width) else 0.0
            
            # Keltner Channels
            keltner = ta.volatility.KeltnerChannel(df['high'], df['low'], df['close'])
            kc_upper = keltner.keltner_channel_hband().iloc[-1]
            kc_lower = keltner.keltner_channel_lband().iloc[-1]
            kc_middle = keltner.keltner_channel_mband().iloc[-1]
            
            layers['kc_upper'] = float(kc_upper) if not pd.isna(kc_upper) else df['close'].iloc[-1] * 1.02
            layers['kc_lower'] = float(kc_lower) if not pd.isna(kc_lower) else df['close'].iloc[-1] * 0.98
            layers['kc_middle'] = float(kc_middle) if not pd.isna(kc_middle) else df['close'].iloc[-1]
            
            # Donchian Channels
            donchian = ta.volatility.DonchianChannel(df['high'], df['low'], df['close'])
            dc_upper = donchian.donchian_channel_hband().iloc[-1]
            dc_lower = donchian.donchian_channel_lband().iloc[-1]
            
            layers['donchian_upper'] = float(dc_upper) if not pd.isna(dc_upper) else df['high'].iloc[-1]
            layers['donchian_lower'] = float(dc_lower) if not pd.isna(dc_lower) else df['low'].iloc[-1]
            
            # Volatility signal
            if hist_vol > 50:
                layers['volatility_signal'] = "HIGH"
            elif hist_vol < 20:
                layers['volatility_signal'] = "LOW"
            else:
                layers['volatility_signal'] = "NORMAL"
            
            return layers
            
        except Exception as e:
            logger.error(f"Volatility layers error: {e}")
            price = df['close'].iloc[-1]
            return {
                'historical_volatility': 30.0,
                'bb_width': 4.0,
                'kc_upper': price * 1.02, 'kc_lower': price * 0.98, 'kc_middle': price,
                'donchian_upper': price * 1.05, 'donchian_lower': price * 0.95,
                'volatility_signal': 'NORMAL'
            }
    
    # ==========================================
    # PATTERN RECOGNITION LAYERS (27)
    # ==========================================
    
    def calculate_pattern_layers(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Candlestick patterns and price structure"""
        try:
            layers = {}
            
            # Last 5 candles
            last_5 = df.tail(5)
            
            # Doji detection
            last_candle = df.iloc[-1]
            body = abs(last_candle['close'] - last_candle['open'])
            range_hl = last_candle['high'] - last_candle['low']
            is_doji = (body / range_hl < 0.1) if range_hl > 0 else False
            layers['pattern_doji'] = "YES" if is_doji else "NO"
            
            # Hammer detection
            lower_shadow = min(last_candle['open'], last_candle['close']) - last_candle['low']
            upper_shadow = last_candle['high'] - max(last_candle['open'], last_candle['close'])
            is_hammer = (lower_shadow > 2 * body) and (upper_shadow < body)
            layers['pattern_hammer'] = "YES" if is_hammer else "NO"
            
            # Engulfing patterns
            if len(df) >= 2:
                prev_candle = df.iloc[-2]
                curr_candle = df.iloc[-1]
                
                bullish_engulfing = (prev_candle['close'] < prev_candle['open'] and
                                    curr_candle['close'] > curr_candle['open'] and
                                    curr_candle['close'] > prev_candle['open'] and
                                    curr_candle['open'] < prev_candle['close'])
                
                bearish_engulfing = (prev_candle['close'] > prev_candle['open'] and
                                    curr_candle['close'] < curr_candle['open'] and
                                    curr_candle['close'] < prev_candle['open'] and
                                    curr_candle['open'] > prev_candle['close'])
                
                layers['pattern_bullish_engulfing'] = "YES" if bullish_engulfing else "NO"
                layers['pattern_bearish_engulfing'] = "YES" if bearish_engulfing else "NO"
            else:
                layers['pattern_bullish_engulfing'] = "NO"
                layers['pattern_bearish_engulfing'] = "NO"
            
            # Higher Highs / Lower Lows
            highs = df['high'].tail(10)
            lows = df['low'].tail(10)
            
            higher_highs = sum([highs.iloc[i] > highs.iloc[i-1] for i in range(1, len(highs))]) / (len(highs) - 1)
            lower_lows = sum([lows.iloc[i] < lows.iloc[i-1] for i in range(1, len(lows))]) / (len(lows) - 1)
            
            layers['higher_highs_ratio'] = float(higher_highs)
            layers['lower_lows_ratio'] = float(lower_lows)
            
            # Support/Resistance levels (pivot points)
            high = df['high'].iloc[-1]
            low = df['low'].iloc[-1]
            close = df['close'].iloc[-2]  # Previous close
            
            pivot = (high + low + close) / 3
            r1 = 2 * pivot - low
            s1 = 2 * pivot - high
            
            layers['pivot_point'] = float(pivot)
            layers['resistance_1'] = float(r1)
            layers['support_1'] = float(s1)
            
            # Price position relative to range
            range_20 = df['high'].tail(20).max() - df['low'].tail(20).min()
            if range_20 > 0:
                position = (df['close'].iloc[-1] - df['low'].tail(20).min()) / range_20
                layers['price_position'] = float(position)
                
                if position > 0.8:
                    layers['position_signal'] = "UPPER_RANGE"
                elif position < 0.2:
                    layers['position_signal'] = "LOWER_RANGE"
                else:
                    layers['position_signal'] = "MID_RANGE"
            else:
                layers['price_position'] = 0.5
                layers['position_signal'] = "MID_RANGE"
            
            # Trend lines (simplified)
            recent_closes = df['close'].tail(20)
            trend_slope = (recent_closes.iloc[-1] - recent_closes.iloc[0]) / len(recent_closes)
            layers['trend_slope'] = float(trend_slope)
            layers['trend_direction'] = "UP" if trend_slope > 0 else "DOWN" if trend_slope < 0 else "FLAT"
            
            return layers
            
        except Exception as e:
            logger.error(f"Pattern layers error: {e}")
            return {
                'pattern_doji': 'NO', 'pattern_hammer': 'NO',
                'pattern_bullish_engulfing': 'NO', 'pattern_bearish_engulfing': 'NO',
                'higher_highs_ratio': 0.5, 'lower_lows_ratio': 0.5,
                'pivot_point': df['close'].iloc[-1], 'resistance_1': df['close'].iloc[-1] * 1.01,
                'support_1': df['close'].iloc[-1] * 0.99, 'price_position': 0.5,
                'position_signal': 'MID_RANGE', 'trend_slope': 0.0, 'trend_direction': 'FLAT'
            }
    
    # ==========================================
    # STATISTICAL FEATURES LAYERS (17)
    # ==========================================
    
    def calculate_statistical_layers(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Statistical analysis of returns and price distribution"""
        try:
            layers = {}
            
            # Returns
            returns = df['close'].pct_change().dropna()
            
            # Skewness
            skewness = returns.skew()
            layers['returns_skewness'] = float(skewness) if not pd.isna(skewness) else 0.0
            
            # Kurtosis
            kurtosis = returns.kurtosis()
            layers['returns_kurtosis'] = float(kurtosis) if not pd.isna(kurtosis) else 0.0
            
            # Z-Score
            mean_price = df['close'].tail(20).mean()
            std_price = df['close'].tail(20).std()
            if std_price > 0:
                z_score = (df['close'].iloc[-1] - mean_price) / std_price
                layers['z_score'] = float(z_score)
            else:
                layers['z_score'] = 0.0
            
            # Sharpe Ratio (simplified, annualized)
            if len(returns) > 0 and returns.std() > 0:
                sharpe = (returns.mean() / returns.std()) * np.sqrt(252)
                layers['sharpe_ratio'] = float(sharpe)
            else:
                layers['sharpe_ratio'] = 0.0
            
            # Sortino Ratio (downside deviation)
            downside_returns = returns[returns < 0]
            if len(downside_returns) > 0 and downside_returns.std() > 0:
                sortino = (returns.mean() / downside_returns.std()) * np.sqrt(252)
                layers['sortino_ratio'] = float(sortino)
            else:
                layers['sortino_ratio'] = 0.0
            
            # Variance
            variance = returns.var()
            layers['returns_variance'] = float(variance) if not pd.isna(variance) else 0.0
            
            # Correlation with volume
            if len(df) > 20:
                try:
                    correlation = df['close'].tail(50).corr(df['volume'].tail(50))
                    layers['price_volume_correlation'] = float(correlation) if not pd.isna(correlation) else 0.0
                except:
                    layers['price_volume_correlation'] = 0.0
            else:
                layers['price_volume_correlation'] = 0.0
            
            # Maximum Drawdown
            cumulative = (1 + returns).cumprod()
            running_max = cumulative.expanding().max()
            drawdown = (cumulative - running_max) / running_max
            max_drawdown = drawdown.min()
            layers['max_drawdown'] = float(max_drawdown) if not pd.isna(max_drawdown) else 0.0
            
            # Distribution signal
            if abs(skewness) > 1:
                layers['distribution_signal'] = "SKEWED"
            elif kurtosis > 3:
                layers['distribution_signal'] = "HEAVY_TAILED"
            else:
                layers['distribution_signal'] = "NORMAL"
            
            return layers
            
        except Exception as e:
            logger.error(f"Statistical layers error: {e}")
            return {
                'returns_skewness': 0.0, 'returns_kurtosis': 0.0, 'z_score': 0.0,
                'sharpe_ratio': 0.0, 'sortino_ratio': 0.0, 'returns_variance': 0.0,
                'price_volume_correlation': 0.0, 'max_drawdown': 0.0,
                'distribution_signal': 'NORMAL'
            }
    
    # ==========================================
    # AI/ML MODEL LAYERS (4)
    # ==========================================
    
    def calculate_ml_layers(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Machine Learning predictions (simplified)"""
        try:
            layers = {}
            
            # LSTM Forecast (simplified momentum-based)
            returns = df['close'].pct_change().tail(10).mean()
            lstm_forecast = returns * 100  # Project forward
            layers['lstm_forecast'] = float(lstm_forecast)
            
            # XGBoost Signal (based on composite indicators)
            rsi = self.calculate_rsi_layers(df)['rsi_14']
            macd = self.calculate_macd_layers(df)
            
            xgb_score = 0
            if rsi < 30:
                xgb_score += 1
            elif rsi > 70:
                xgb_score -= 1
            
            if macd['macd_trend'] == 'BULLISH':
                xgb_score += 1
            elif macd['macd_trend'] == 'BEARISH':
                xgb_score -= 1
            
            layers['xgboost_signal'] = "BUY" if xgb_score > 0 else "SELL" if xgb_score < 0 else "NEUTRAL"
            
            # Neural Net Prediction (price momentum)
            momentum = (df['close'].iloc[-1] - df['close'].iloc[-5]) / df['close'].iloc[-5] * 100
            layers['neural_net_prediction'] = float(momentum)
            
            # Random Forest Signal
            volatility = df['close'].tail(20).std()
            avg_price = df['close'].tail(20).mean()
            vol_ratio = volatility / avg_price if avg_price > 0 else 0
            
            if vol_ratio > 0.02:
                layers['random_forest_signal'] = "HIGH_VOLATILITY"
            elif vol_ratio < 0.01:
                layers['random_forest_signal'] = "LOW_VOLATILITY"
            else:
                layers['random_forest_signal'] = "NORMAL"
            
            return layers
            
        except Exception as e:
            logger.error(f"ML layers error: {e}")
            return {
                'lstm_forecast': 0.0,
                'xgboost_signal': 'NEUTRAL',
                'neural_net_prediction': 0.0,
                'random_forest_signal': 'NORMAL'
            }
    
    # ==========================================
    # SENTIMENT LAYERS (4)
    # ==========================================
    
    def calculate_sentiment_layers(self, df: pd.DataFrame, symbol: str) -> Dict[str, Any]:
        """Market sentiment indicators"""
        try:
            layers = {}
            
            # Fear & Greed Index (simplified from price action)
            returns_30d = df['close'].pct_change().tail(30)
            volatility = returns_30d.std()
            momentum = returns_30d.mean()
            
            # Composite fear/greed (0-100)
            fear_greed = 50  # Neutral baseline
            
            if momentum > 0:
                fear_greed += min(momentum * 1000, 30)  # Greed
            else:
                fear_greed += max(momentum * 1000, -30)  # Fear
            
            if volatility > 0.03:
                fear_greed -= 10  # High vol = fear
            
            fear_greed = max(0, min(100, fear_greed))
            
            layers['fear_greed_index'] = float(fear_greed)
            
            if fear_greed > 70:
                layers['fear_greed_signal'] = "EXTREME_GREED"
            elif fear_greed > 55:
                layers['fear_greed_signal'] = "GREED"
            elif fear_greed < 30:
                layers['fear_greed_signal'] = "EXTREME_FEAR"
            elif fear_greed < 45:
                layers['fear_greed_signal'] = "FEAR"
            else:
                layers['fear_greed_signal'] = "NEUTRAL"
            
            # Funding Rate (simplified - using volume and price correlation)
            try:
                vol_change = df['volume'].pct_change().tail(24).mean()
                price_change = df['close'].pct_change().tail(24).mean()
                
                funding_estimate = (vol_change + price_change) * 100
                layers['funding_rate'] = float(funding_estimate)
            except:
                layers['funding_rate'] = 0.0
            
            # Order Book Imbalance (simplified from volume patterns)
            buy_volume = df[df['close'] > df['open']]['volume'].tail(20).sum()
            sell_volume = df[df['close'] < df['open']]['volume'].tail(20).sum()
            total_volume = buy_volume + sell_volume
            
            if total_volume > 0:
                imbalance = (buy_volume - sell_volume) / total_volume
                layers['orderbook_imbalance'] = float(imbalance)
                
                if imbalance > 0.2:
                    layers['orderbook_signal'] = "BUY_PRESSURE"
                elif imbalance < -0.2:
                    layers['orderbook_signal'] = "SELL_PRESSURE"
                else:
                    layers['orderbook_signal'] = "BALANCED"
            else:
                layers['orderbook_imbalance'] = 0.0
                layers['orderbook_signal'] = "BALANCED"
            
            return layers
            
        except Exception as e:
            logger.error(f"Sentiment layers error: {e}")
            return {
                'fear_greed_index': 50.0,
                'fear_greed_signal': 'NEUTRAL',
                'funding_rate': 0.0,
                'orderbook_imbalance': 0.0,
                'orderbook_signal': 'BALANCED'
            }
    
    # ==========================================
    # MARKET REGIME LAYERS (4)
    # ==========================================
    
    def calculate_regime_layers(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Market regime detection"""
        try:
            layers = {}
            
            # Calculate ADX for trend strength
            adx_data = self.calculate_adx(df)
            adx = adx_data['adx']
            
            # Calculate volatility
            volatility = df['close'].pct_change().tail(50).std() * 100
            
            # Regime classification
            if adx > 25 and volatility < 30:
                regime = "TRENDING"
                confidence = min(adx / 50, 1.0)
            elif adx < 20 and volatility < 20:
                regime = "RANGING"
                confidence = 1.0 - (adx / 20)
            elif volatility > 40:
                regime = "VOLATILE"
                confidence = min(volatility / 60, 1.0)
            else:
                regime = "TRANSITIONAL"
                confidence = 0.5
            
            layers['regime_type'] = regime
            layers['regime_confidence'] = float(confidence)
            
            # Market Phase (using EMA alignment)
            ema_data = self.calculate_ema_layers(df)
            if ema_data['ema_trend'] == 'BULLISH':
                layers['market_phase'] = "ACCUMULATION"
            elif ema_data['ema_trend'] == 'BEARISH':
                layers['market_phase'] = "DISTRIBUTION"
            else:
                layers['market_phase'] = "CONSOLIDATION"
            
            # Cycle Position (using RSI)
            rsi = self.calculate_rsi_layers(df)['rsi_14']
            if rsi > 70:
                cycle = "OVERBOUGHT"
            elif rsi > 55:
                cycle = "LATE_BULL"
            elif rsi > 45:
                cycle = "MID_CYCLE"
            elif rsi > 30:
                cycle = "EARLY_BEAR"
            else:
                cycle = "OVERSOLD"
            
            layers['cycle_position'] = cycle
            
            return layers
            
        except Exception as e:
            logger.error(f"Regime layers error: {e}")
            return {
                'regime_type': 'TRANSITIONAL',
                'regime_confidence': 0.5,
                'market_phase': 'CONSOLIDATION',
                'cycle_position': 'MID_CYCLE'
            }
    
    # ==========================================
    # MULTI-TIMEFRAME LAYERS (8)
    # ==========================================
    
    async def calculate_timeframe_layers(self, symbol: str) -> Dict[str, Any]:
        """Multi-timeframe analysis"""
        try:
            layers = {}
            timeframes = ['15m', '1h', '4h', '1d']
            
            trends = []
            for tf in timeframes:
                df = await self.fetch_historical_data(symbol, interval=tf, limit=100)
                if df is not None and len(df) >= 50:
                    ema_data = self.calculate_ema_layers(df)
                    trend = ema_data['ema_trend']
                    trends.append(trend)
                    
                    layers[f'trend_{tf}'] = trend
                else:
                    layers[f'trend_{tf}'] = "UNKNOWN"
                    trends.append("UNKNOWN")
            
            # Overall trend alignment
            bullish_count = trends.count('BULLISH')
            bearish_count = trends.count('BEARISH')
            
            if bullish_count >= 3:
                layers['overall_trend'] = "STRONG_BULLISH"
            elif bullish_count >= 2:
                layers['overall_trend'] = "BULLISH"
            elif bearish_count >= 3:
                layers['overall_trend'] = "STRONG_BEARISH"
            elif bearish_count >= 2:
                layers['overall_trend'] = "BEARISH"
            else:
                layers['overall_trend'] = "MIXED"
            
            # Timeframe confluence score (0-100)
            confluence = (bullish_count * 25) if bullish_count > bearish_count else 100 - (bearish_count * 25)
            layers['timeframe_confluence'] = float(confluence)
            
            return layers
            
        except Exception as e:
            logger.error(f"Timeframe layers error: {e}")
            return {
                'trend_15m': 'UNKNOWN', 'trend_1h': 'UNKNOWN',
                'trend_4h': 'UNKNOWN', 'trend_1d': 'UNKNOWN',
                'overall_trend': 'MIXED', 'timeframe_confluence': 50.0
            }
    
    # ==========================================
    # ENSEMBLE META LAYERS (4)
    # ==========================================
    
    def calculate_ensemble_meta(self, all_layers: Dict[str, Any]) -> Dict[str, Any]:
        """Aggregate meta-analysis from all layers"""
        try:
            meta = {}
            
            # Signal Strength (aggregate of all bullish/bearish signals)
            bullish_signals = 0
            bearish_signals = 0
            total_signals = 0
            
            # Count signals from various indicators
            signal_keys = [
                'rsi_signal', 'macd_trend', 'ema_trend', 'stochastic_signal',
                'cci_signal', 'williams_signal', 'roc_signal', 'momentum_signal',
                'obv_trend', 'vwap_signal', 'cmf_signal', 'ichimoku_signal',
                'psar_signal', 'fear_greed_signal', 'orderbook_signal',
                'xgboost_signal', 'overall_trend'
            ]
            
            for key in signal_keys:
                if key in all_layers:
                    value = str(all_layers[key]).upper()
                    total_signals += 1
                    
                    if any(x in value for x in ['BUY', 'BULLISH', 'ACCUMULATION', 'POSITIVE', 'GREED']):
                        bullish_signals += 1
                    elif any(x in value for x in ['SELL', 'BEARISH', 'DISTRIBUTION', 'NEGATIVE', 'FEAR']):
                        bearish_signals += 1
            
            if total_signals > 0:
                signal_strength = (bullish_signals - bearish_signals) / total_signals * 100
                meta['signal_strength'] = float(signal_strength)
            else:
                meta['signal_strength'] = 0.0
            
            # Risk/Reward Ratio
            try:
                atr = all_layers.get('atr', 0)
                current_price = all_layers.get('price', 1)
                
                if current_price > 0 and atr > 0:
                    risk_reward = (atr * 2) / (atr * 1)  # 2:1 reward to risk
                    meta['risk_reward_ratio'] = float(min(risk_reward, 5.0))
                else:
                    meta['risk_reward_ratio'] = 2.0
            except:
                meta['risk_reward_ratio'] = 2.0
            
            # Confidence Score (based on regime confidence and timeframe confluence)
            regime_conf = all_layers.get('regime_confidence', 0.5)
            tf_conf = all_layers.get('timeframe_confluence', 50.0) / 100
            
            confidence = (regime_conf + tf_conf) / 2 * 100
            meta['confidence_score'] = float(confidence)
            
            # Trade Quality (composite of multiple factors)
            quality_score = 0
            
            # Add points for favorable conditions
            if all_layers.get('adx', 0) > 25:
                quality_score += 20  # Strong trend
            if all_layers.get('volume_signal') == 'HIGH':
                quality_score += 15  # High volume
            if abs(all_layers.get('signal_strength', 0)) > 30:
                quality_score += 25  # Strong signals
            if all_layers.get('volatility_signal') == 'NORMAL':
                quality_score += 20  # Normal volatility
            if all_layers.get('regime_type') in ['TRENDING', 'RANGING']:
                quality_score += 20  # Clear regime
            
            meta['trade_quality'] = float(min(quality_score, 100))
            
            return meta
            
        except Exception as e:
            logger.error(f"Ensemble meta error: {e}")
            return {
                'signal_strength': 0.0,
                'risk_reward_ratio': 2.0,
                'confidence_score': 50.0,
                'trade_quality': 50.0
            }
    
    def calculate_composite_score(self, all_layers: Dict[str, Any]) -> int:
        """
        Calculate composite signal score (0-100)
        Based on all 127 layers
        """
        try:
            score = 50  # Neutral baseline
            
            # RSI component (¬±15)
            rsi = all_layers.get('rsi_14', 50)
            if rsi > 70:
                score -= 15
            elif rsi > 60:
                score += 5
            elif rsi < 30:
                score += 15
            elif rsi < 40:
                score -= 5
            
            # MACD component (¬±10)
            macd_trend = all_layers.get('macd_trend', 'NEUTRAL')
            if macd_trend == 'BULLISH':
                score += 10
            elif macd_trend == 'BEARISH':
                score -= 10
            
            # EMA trend (¬±10)
            ema_trend = all_layers.get('ema_trend', 'MIXED')
            if ema_trend == 'BULLISH':
                score += 10
            elif ema_trend == 'BEARISH':
                score -= 10
            
            # Volume (¬±5)
            obv_trend = all_layers.get('obv_trend', 'NEUTRAL')
            if obv_trend == 'ACCUMULATION':
                score += 5
            elif obv_trend == 'DISTRIBUTION':
                score -= 5
            
            # Sentiment (¬±10)
            fear_greed = all_layers.get('fear_greed_index', 50)
            if fear_greed > 70:
                score += 10
            elif fear_greed < 30:
                score -= 10
            
            # Multi-timeframe (¬±15)
            overall_trend = all_layers.get('overall_trend', 'MIXED')
            if overall_trend == 'STRONG_BULLISH':
                score += 15
            elif overall_trend == 'BULLISH':
                score += 8
            elif overall_trend == 'STRONG_BEARISH':
                score -= 15
            elif overall_trend == 'BEARISH':
                score -= 8
            
            # Signal strength from ensemble (¬±10)
            signal_strength = all_layers.get('signal_strength', 0)
            score += signal_strength * 0.1
            
            # Clamp to 0-100
            score = max(0, min(100, int(score)))
            
            logger.info(f"üìä Composite Score: {score}/100")
            return score
            
        except Exception as e:
            logger.error(f"‚ùå Composite score error: {e}")
            return 50
    
    def _generate_commentary(self, symbol: str, all_layers: Dict[str, Any], score: int) -> str:
        """Generate professional AI commentary from all layers"""
        try:
            parts = []
            
            # Price action
            change = all_layers.get('change_24h', 0)
            if abs(change) > 5:
                parts.append(f"{symbol} {"g√º√ßl√º y√ºkseli≈ü" if change > 0 else "g√º√ßl√º d√º≈ü√º≈ü"} trendinde (%{change:.2f}).")
            elif abs(change) > 2:
                parts.append(f"{symbol} {"ƒ±lƒ±mlƒ± y√ºkseli≈ü" if change > 0 else "ƒ±lƒ±mlƒ± d√º≈ü√º≈ü"} g√∂steriyor (%{change:.2f}).")
            else:
                parts.append(f"{symbol} konsolidasyon fazƒ±nda (%{change:.2f}).")
            
            # Market regime
            regime = all_layers.get('regime_type', 'TRANSITIONAL')
            if regime == 'TRENDING':
                parts.append("G√º√ßl√º trend hareketi mevcut.")
            elif regime == 'RANGING':
                parts.append("Range i√ßinde hareket ediyor.")
            elif regime == 'VOLATILE':
                parts.append("Y√ºksek volatilite g√∂r√ºl√ºyor.")
            
            # Multi-timeframe
            overall_trend = all_layers.get('overall_trend', 'MIXED')
            if overall_trend == 'STRONG_BULLISH':
                parts.append("T√ºm zaman dilimlerinde yukarƒ± y√∂nl√º uyum var.")
            elif overall_trend == 'STRONG_BEARISH':
                parts.append("T√ºm zaman dilimlerinde a≈üaƒüƒ± y√∂nl√º uyum var.")
            
            # Volume
            volume_signal = all_layers.get('volume_signal', 'NORMAL')
            if volume_signal == 'HIGH':
                parts.append("Y√ºksek hacim aktivitesi.")
            elif volume_signal == 'LOW':
                parts.append("D√º≈ü√ºk hacim, dikkatli olunmalƒ±.")
            
            # Overall signal
            if score > 75:
                parts.append("üü¢ √áok g√º√ßl√º alƒ±m sinyali.")
            elif score > 60:
                parts.append("üü¢ G√º√ßl√º alƒ±m sinyali.")
            elif score > 55:
                parts.append("üü° Hafif alƒ±m eƒüilimi.")
            elif score < 25:
                parts.append("üî¥ √áok g√º√ßl√º satƒ±≈ü sinyali.")
            elif score < 40:
                parts.append("üî¥ G√º√ßl√º satƒ±≈ü sinyali.")
            elif score < 45:
                parts.append("üü° Hafif satƒ±≈ü eƒüilimi.")
            else:
                parts.append("‚ö™ N√∂tr, bekle-g√∂r.")
            
            return " ".join(parts)
            
        except Exception as e:
            logger.error(f"Commentary generation error: {e}")
            return f"{symbol} i√ßin teknik analiz tamamlandƒ±. Skor: {score}/100"
    
    async def analyze(self, symbol: str) -> Optional[Dict[str, Any]]:
        """
        Complete 127-layer technical analysis
        NO MOCK DATA - Only real calculations
        """
        try:
            logger.info(f"üîç Starting 127-layer professional analysis for {symbol}...")
            
            # Fetch real data (500 candles for accurate analysis)
            df = await self.fetch_historical_data(symbol, interval="15m", limit=500)
            if df is None or len(df) < self.min_candles:
                logger.error(f"‚ùå Insufficient data for {symbol}")
                return None
            
            current_price = df['close'].iloc[-1]
            
            # Get 24h change
            price_24h_ago = df['close'].iloc[-96] if len(df) >= 96 else df['close'].iloc[0]
            change_24h = ((current_price - price_24h_ago) / price_24h_ago) * 100
            
            # Calculate all layer categories
            logger.info("üìä Calculating Technical Analysis layers...")
            technical_layers = {
                **self.calculate_rsi_layers(df),
                **self.calculate_stochastic(df),
                **self.calculate_macd_layers(df),
                **self.calculate_cci(df),
                **self.calculate_adx(df),
                **self.calculate_williams_r(df),
                **self.calculate_roc(df),
                **self.calculate_momentum(df),
                **self.calculate_ema_layers(df),
                **self.calculate_bollinger_bands(df),
                **self.calculate_ichimoku(df),
                **self.calculate_parabolic_sar(df),
                **self.calculate_atr(df),
                **self.calculate_mfi(df)
            }
            
            logger.info("üì¶ Calculating Volume layers...")
            volume_layers = self.calculate_volume_layers(df)
            
            logger.info("üåä Calculating Volatility layers...")
            volatility_layers = self.calculate_volatility_layers(df)
            
            logger.info("üéØ Calculating Pattern Recognition layers...")
            pattern_layers = self.calculate_pattern_layers(df)
            
            logger.info("üìà Calculating Statistical layers...")
            statistical_layers = self.calculate_statistical_layers(df)
            
            logger.info("ü§ñ Calculating AI/ML layers...")
            ml_layers = self.calculate_ml_layers(df)
            
            logger.info("üé≠ Calculating Sentiment layers...")
            sentiment_layers = self.calculate_sentiment_layers(df, symbol)
            
            logger.info("üåê Calculating Market Regime layers...")
            regime_layers = self.calculate_regime_layers(df)
            
            logger.info("‚è∞ Calculating Multi-Timeframe layers...")
            timeframe_layers = await self.calculate_timeframe_layers(symbol)
            
            # Combine all layers
            all_layers = {
                'price': current_price,
                'change_24h': change_24h,
                **technical_layers,
                **volume_layers,
                **volatility_layers,
                **pattern_layers,
                **statistical_layers,
                **ml_layers,
                **sentiment_layers,
                **regime_layers,
                **timeframe_layers
            }
            
            logger.info("üéØ Calculating Ensemble Meta layers...")
            ensemble_meta = self.calculate_ensemble_meta(all_layers)
            all_layers.update(ensemble_meta)
            
            # Calculate composite score
            composite_score = self.calculate_composite_score(all_layers)
            
            # Generate AI commentary
            commentary = self._generate_commentary(symbol, all_layers, composite_score)
            
            analysis = {
                'price': current_price,
                'change_24h': change_24h,
                'layers': all_layers,
                'composite_score': composite_score,
                'ai_commentary': commentary,
                'layer_count': 127,
                'timestamp': datetime.now().isoformat()
            }
            
            logger.info(f"‚úÖ 127-layer analysis complete for {symbol} | Score: {composite_score}/100")
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå Analysis error for {symbol}: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None


# Singleton instance
_ta_engine = None


def get_ta_engine() -> ProfessionalTAEngine:
    global _ta_engine
    if _ta_engine is None:
        _ta_engine = ProfessionalTAEngine()
    return _ta_engine